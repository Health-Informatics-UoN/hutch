import { Callout, Tabs, Table, Td, Th, Tr, Code } from "nextra/components";
import { Steps } from "nextra/components";

# Getting started with Bunny

This page will guide you through getting Bunny running locally.

Start by cloning [the Bunny repository](https://github.com/Health-Informatics-UoN/hutch-bunny)

## Prerequisites

- Bunny runs on Python version 3.13
- Dependencies are managed with [uv](https://github.com/astral-sh/uv), which needs to be installed if you run Bunny outside a container.
- Bunny needs to query a database
  - A remote OMOP-CDM database running
  - Or a tarball containing a `pg_dump` of an OMOP-CDM database

## OMOP-CDM setup

Before Bunny can get up and running, it needs a database to query.
If you don't have a real OMOP-CDM, you can run a mock database.

### Mock database setup

<Steps>
#### Start a containerized database

The `compose.yml` in the root of the Hutch tools repository can start a database container with

```bash copy
docker compose up db
```

This will initialise a Postgres instance in the container.

<Callout type="info">
  These instructions assume you have a pre-existing OMOP CDM Postgresql database
  and it can be called `hutch_db.tar`, for example, as below.
</Callout>

#### Copy the data

Navigate to the folder containing `hutch_db.tar` and copy it into the container with:

```bash copy
docker cp hutch_db.tar hutch-bunny-dev-db-1:/
```

#### Start running bash in your container

```bash copy
docker exec -it hutch-bunny-dev-db-1 bash
```

#### Use pg_restore to load the data into the database

```bash copy
pg_restore --dbname=postgres --host=localhost --port=5432 --username=postgres --password hutch_db.tar
```

If prompted, provide "postgres" as a password

You can then exit the container with `ctrl+d` or `exit`

</Steps>

## Environment configuration

To run Bunny locally, your environment needs to have some variables configured.

<Steps>
### Create a file called .env in app/bunny
The file should contain the variables required to connect to a database and Relay.

For example, if using the containerized Relay and mock database:

```sh copy
DATASOURCE_DB_USERNAME=postgres
DATASOURCE_DB_PASSWORD=postgres
DATASOURCE_DB_DATABASE=postgres
DATASOURCE_DB_DRIVERNAME=postgresql
DATASOURCE_DB_SCHEMA=public
DATASOURCE_DB_PORT=5432
DATASOURCE_DB_HOST=localhost
TASK_API_BASE_URL=http://localhost:8080
TASK_API_USERNAME=username
TASK_API_PASSWORD=password
LOW_NUMBER_SUPPRESSION_THRESHOLD=
ROUNDING_TARGET=
POLLING_INTERVAL=5
```

If you are querying a remote database, the variables prefixed with `DATASOURCE` must be configured accordingly.
If you use another method to set your environment variables, follow the example above.

</Steps>
## Installing dependencies
The first time you run Bunny outside a container, you will need to install its dependencies by running
```bash copy
uv pip install .
```

## Running the Docker daemon

Bunny has a daemon which polls [Relay](/relay) for jobs, so needs to have a Relay instance running.

<Steps>
### Start the Relay container

The compose used to start up the database also contains an implementation of Relay.

```bash copy
docker compose up relay -d
```

### Run the Bunny daemon

The Bunny daemon can then be run using uv. This will ensure the dependencies and environment variables are loaded.

```bash copy
uv run bunny-daemon
```

You should then see a message in your console like this:

```bash
INFO - 12-Nov-24 12:36:24 - Setting up database connection...
INFO - 12-Nov-24 12:36:24 - Looking for job...
INFO - 12-Nov-24 12:36:29 - Job received. Resolving...
INFO - 12-Nov-24 12:36:29 - Processing query...
INFO - 12-Nov-24 12:36:30 - Solved availability query
INFO - 12-Nov-24 12:36:30 - Job resolved.
INFO - 12-Nov-24 12:36:35 - Looking for job...
INFO - 12-Nov-24 12:36:40 - Looking for job...
INFO - 12-Nov-24 12:36:45 - Looking for job...
```

Bunny establishes a connection to your OMOP-CDM database, then polls Relay for a job.
When it receives a job, it processes the query, queries the database, and sends the result back to Relay.
You won't see the results here, but if you see the messages, then it's successfully contacting both the database and Relay.

</Steps>

<Callout emoji="ðŸŽ‰">Congratulations on your first Bunny query!</Callout>

## Running bunny-cli

To run Bunny without Relay, the command-line interface can be used.
This needs a file with the right JSON schema to run (example below).

### How to run

<Tabs items={['Docker', 'From Source']}>
  <Tabs.Tab>
    You can use the CLI from the same image as the daemon, by overriding the `entrypoint`.

    You will need to have made the input file available to the docker container, for example by mounting a volume.

    It is possible to pass Docker arguments to `docker run` **before** the image, and arguments to the Bunny CLI **after** the image.

    Here's an example with `docker run`:

    ```bash copy
    docker run \
    -v <path/to/rquest-query.json>:./rquest-query.json \
    --entrypoint uv \
    ghcr.io/health-informatics-uon/hutch/bunny:<TAG> \
    run bunny-cli --body ./rquest-query.json
    ```

  </Tabs.Tab>
  <Tabs.Tab>
    To run the CLI, navigate to `hutch-cohort-discovery/app/bunny`

    Then run

    ```bash copy
    uv run bunny-cli --body <path/to/rquest-query.json>
    ```

    This should write a result for your query to `app/bunny/output.json`

  </Tabs.Tab>
</Tabs>

### Sample input files

```json copy filename="availability.json"
{
  "task_id": "job-2023-01-13-14: 20: 38-project",
  "project": "project_id",
  "owner": "user1",
  "cohort": {
    "groups": [
      {
        "rules": [
          {
            "varname": "OMOP",
            "varcat": "Person",
            "type": "TEXT",
            "oper": "=",
            "value": "8507"
          }
        ],
        "rules_oper": "AND"
      }
    ],
    "groups_oper": "OR"
  },
  "collection": "collection_id",
  "protocol_version": "v2",
  "char_salt": "salt",
  "uuid": "unique_id"
}
```
